{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of quarantine information from NOTAMs\n",
    "\n",
    "\n",
    "In this notebook, we use the preprocessed NOTAMs dataset to search for the terms \"quarantine\" and \"isolate\" in the messages and add those messages to a separate column in the dataframe. We also run Named Entity Recognition on the filtered text to identify DATE tags. The intention in identifying DATE tags is based on the assumption that the DATE tag would correspond to quarantine duration. \n",
    "\n",
    "\n",
    "**Input**\n",
    "\n",
    "To generate the input dataset, refer this notebook: ws2_snr_NOTAMs_1_data_preparation\n",
    "\n",
    "Preprocessed datasets\n",
    "\n",
    "    - valid_airport_notams_xx.csv\n",
    "    - valid_airspace_notams_xx.csv\n",
    "\n",
    "**Output**\n",
    "\n",
    "    - valid_airport_notams_with_quarantine_xx.csv\n",
    "    - valid_airspace_notams_with_quarantine_xx.csv\n",
    "\n",
    "Datasets with additional columns corresponding to quarantine related text\n",
    "\n",
    "\n",
    "The following steps are carried out:\n",
    "\n",
    "1. Read the preprocessed datset\n",
    "\n",
    "2. Extract quarantine related text\n",
    "\n",
    "3. Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import ast\n",
    "\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import plac\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from spacy import displacy\n",
    "import seaborn as sbs\n",
    "import geonamescache\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Read the preprocessed datset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_df = pd.read_csv(\"/project_data/data_asset/ws2/notams/valid_airport_notams_20200717.csv\")\n",
    "asp_df = pd.read_csv(\"/project_data/data_asset/ws2/notams/valid_airspace_notams_20200717.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Extract quarantine related text**\n",
    "\n",
    "- Load spacy\n",
    "\n",
    "- Filter for text containing the terms \"quarantine\" and \"isolation\"\n",
    "\n",
    "- Extract DATE (DAY or WEEK) tags for the filtered text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#Stop words#\n",
    "############\n",
    "\n",
    "nlp_ = spacy.load('en_core_web_md')\n",
    "\n",
    "# Adding stop words\n",
    "new_stop_words = [\"create\",\"source\",\"euecyiyn\",'etczyoyx','tel']\n",
    "\n",
    "# Add airport codes to stop words\n",
    "new_stop_words.extend([ac.lower() for ac in list(apt_df.airportCode.values)])\n",
    "\n",
    "for new_word in new_stop_words:\n",
    "    nlp_.vocab[new_word].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarantine_info(df):\n",
    "    quarantine_duration_df = df.copy()\n",
    "    quarantine_duration_df['quarantine_text'] = \"\"\n",
    "    quarantine_duration_df['quarantine_days'] = \"\"\n",
    "    for idx, row in quarantine_duration_df.iterrows():\n",
    "        quarantine_days = []\n",
    "        quarantine_text = []\n",
    "        message = row['cleaned_message']\n",
    "        doc_ = nlp_(message)\n",
    "        if ('quarantine' in row['tokens']) | ('isolation' in row['tokens']):\n",
    "            for ent in doc_.ents:\n",
    "                if (ent.label_ == \"DATE\") & ((\"DAY\" in ent.text.upper())|(\"WEEK\" in ent.text.upper())):\n",
    "                    quarantine_days.append(ent.text)\n",
    "                    quarantine_text.append(message)\n",
    "                    #spacy.displacy.render(doc_, jupyter=True, style='ent',options={'ents':['DATE']})\n",
    "        if not len(quarantine_days) == 0:\n",
    "            quarantine_duration_df.loc[idx,'quarantine_days'] = \",\".join(quarantine_days)\n",
    "        if not len(quarantine_text) == 0:\n",
    "            quarantine_duration_df.loc[idx,'quarantine_text'] = \" \".join(quarantine_text)\n",
    "\n",
    "    return quarantine_duration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_df = extract_quarantine_info(apt_df)\n",
    "asp_df = extract_quarantine_info(asp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Save the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_df.to_csv(\"/project_data/data_asset/ws2/notams/valid_airport_notams_with_quarantine_20200717.csv\",index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "asp_df.to_csv(\"/project_data/data_asset/ws2/notams/valid_airspace_notams_with_quarantine_20200717.csv\",index=False,quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apt_df[apt_df.quarantine_days != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airport NOTAMS\n",
    "\n",
    "* NOTE: for some rows the quarantine_days column might not correspond to the quarantine duration but to some other date tags in the text!\n",
    "\n",
    "* From the above dataframe, we see that for most cases the quarantine duration corresponds to 14 days. The text has to be read to get the exact quarantine regulations\n",
    "\n",
    "* Further work to be done on identifying different quarantine restrictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asp_df[asp_df.quarantine_days != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airspace NOTAMS\n",
    "\n",
    "\n",
    "- Norway has a quarantine duration of 10 days\n",
    "\n",
    "- South Africa has a quarantine duration of upto 21 days\n",
    "\n",
    "- In some cases there is mention of 7 and 14 days in the message. The message has to be read to understand the exact quarantine regulation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**\n",
    "\n",
    "* Shri Nishanth Rajendran - AI Development Specialist, RÂ² Data Labs, Rolls Royce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
