{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Calculate sentiment and emotion in Meltwater data\n","\n","In this notebook we estimate the sentiment and emotion scores on the extraction from Meltwater. _Sentiment_ is a metric ranging from -1 to 1, where -1 represents a negative view of the topic being discussed in the text that the sentiment score is calculated upon, whilst 1 corresponds to a positive treatment of that text. We also estimate five emotions: anger, disgust, fear, joy and sadness. A text can present different emotions to a certain extent. Hence, the scores range from 0 to 1 and should add up to at most 1. \n","\n","#### Input\n","- Dataset with processed tweets from Meltwater (see notebook `Clean Twitter Data from Meltwater`): `Meltwater_processed.csv`\n","\n","#### Output\n","- Input dataset extended with extra columns containing sentiment (-1 to 1) and emotion scores (5, from 0 to 1): `tweets_emotions_Notts_Melt_ALL.csv`. The scores are only calculated for Nottingham only. \n"]},{"metadata":{},"cell_type":"markdown","source":["## 1. Preliminaries\n","\n","Here we just install some packages that are not present by default in our environment. Then, we import all packages, set up our NLU service and read data."]},{"metadata":{},"cell_type":"code","source":["!pip install ibm_watson\n","!pip install watson_developer_cloud\n","!pip install ibm_cloud_sdk_core"],"execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os  \n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from ibm_watson import NaturalLanguageUnderstandingV1\n","from watson_developer_cloud.natural_language_understanding_v1 import Features, EntitiesOptions, KeywordsOptions, SemanticRolesOptions, SentimentOptions, EmotionOptions, ConceptsOptions, CategoriesOptions\n","from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"],"execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Watson NLU API key\n","API = {\n","  \"apikey\": \"XXXXXXXXXXXXXXX\",\n","  \"iam_apikey_description\": \"XXXXXXXXXXXXXXX\",\n","  \"iam_apikey_name\": \"XXXXXXXXXXXXXXX\",\n","  \"iam_role_crn\": \"XXXXXXXXXXXXXXX\",\n","  \"iam_serviceid_crn\": \"XXXXXXXXXXXXXXX\",\n","  \"url\": \"XXXXXXXXXXXXXXX\"\n","}\n","\n","\n","api_key = API['apikey']\n","url = API['url']\n","\n","natural_language_understanding = NaturalLanguageUnderstandingV1(version='2020-10-29', authenticator=IAMAuthenticator(api_key))\n","natural_language_understanding.set_service_url(url)"],"execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Read data\n","df_proc = pd.read_csv('/project_data/data_asset/Meltwater_processed.csv')\n","df_proc = df_proc[df_proc['City'] == 'Nottingham']\n","df_proc.head()"],"execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. Extract sentiment and emotion"]},{"metadata":{},"cell_type":"code","source":["# Define functions\n","\n","def analyze_using_NLU(analysistext):\n","  \"\"\" \n","  Extract results from Watson Natural Language Understanding. Returns a dictionary with sentiment and emotion scores. \n","  \"\"\"\n","\n","  res=dict()\n","  response = natural_language_understanding.analyze(text=analysistext,\n","                                                    features=Features(\n","                                                        sentiment=SentimentOptions(),\n","                                                        emotion=EmotionOptions()), \n","                                                    language='en')\n","  res['results']=response\n","  return res['results']\n","\n","\n","def get_values_from_NLU(df_orig, col_name):  \n","    \"\"\" \n","    Pass results from analyze_using_NLU to a dataframe\n","    \"\"\"\n","    df = df_orig.copy()\n","\n","    sadness = []\n","    joy = []\n","    fear = []\n","    disgust = []\n","    anger = []\n","    sentiment = []\n","    \n","    count = 1\n","\n","    for i in range(0, len(df)):\n","        if count % 10 == 0: \n","            print('Pass number:', count) # Print progress\n","        txt = df[col_name].iloc[i]\n","        time.sleep(0.5) # Sleep some time not to overload the server\n","        dictionary = analyze_using_NLU(txt)\n","\n","        sadness.append(dictionary.result['emotion']['document']['emotion']['sadness'])\n","        joy.append(dictionary.result['emotion']['document']['emotion']['joy'])\n","        fear.append(dictionary.result['emotion']['document']['emotion']['fear'])\n","        disgust.append(dictionary.result['emotion']['document']['emotion']['disgust'])\n","        anger.append(dictionary.result['emotion']['document']['emotion']['anger'])\n","        sentiment.append(dictionary.result['sentiment']['document']['score'])\n","        \n","        count += 1\n","\n","    df['sadness'] = sadness \n","    df['joy'] = joy\n","    df['fear'] = fear \n","    df['disgust'] = disgust\n","    df['anger'] = anger\n","    df['sentiment'] = sentiment\n","    \n","    df.reset_index(inplace=True)\n","    \n","    return df"],"execution_count":68,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["# Get sentiment and emotions\n","# Produce emotions in batches. Doing in batches in not really necessary - This ensures that we don't overload the server plus we have checkpoints if it is overloaded in the end\n","tweets_emotions = pd.DataFrame()\n","_df_list = list(np.linspace(0, len(df_proc), 100, dtype = int))\n","start = 0\n","batch_count = 1\n","for point in _df_list:\n","    print('Batch:', batch_count)\n","    batch_emotions = get_values_from_NLU(df_proc[start:point+1],'Text_comment')\n","    tweets_emotions = tweets_emotions.append(batch_emotions)\n","    start = point+1\n","    batch_count +=1\n","    print('\\n')\n","    \n","# Produce all emotions in one batch\n","# tweets_emotions = get_values_from_NLU(df_proc,'Text_comment')\n"],"execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Export tweets and emotions\n","tweets_emotions.to_csv('/project_data/data_asset/tweets_emotions_Notts_Melt_ALL.csv', index = False)"],"execution_count":6,"outputs":[]},{"source":["________\n","\n","#### Authors\n","- **Álvaro Corrales Cano** is a Data Scientist within IBM's Cloud Pak Acceleration team. With a background in Economics, Álvaro specialises in a wide array Econometric techniques and causal inference, including regression, discrete choice models, time series and duration analysis.\n","- **Anthony Ayanwale** is a Data Scientist within IBM's Cloud Pak Acceleration team, where he specialises in Data Science and Machine Learning Solutions. \n","- **Nicolas Ayoub** is a Data Scientist within IBM's Cloud Pak Acceleration team, where he specialises in Data Science and Machine Learning Solutions.\n","\n","Copyright © IBM Corp. 2020. Licensed under the Apache License, Version 2.0. Released as licensed Sample Materials.\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.4-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}