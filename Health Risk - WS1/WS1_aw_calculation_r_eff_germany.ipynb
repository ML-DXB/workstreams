{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calculation of the R_eff numbers for Germany (overall and on regional level)\n",
    "\n",
    "## Objective\n",
    "To be able to understand and later foresee government decisions on lockdown measures, we need to look at the same metrics as governments do. Among others as active cases or intensive care units, this is also the (effective) reproduction number.\n",
    "\n",
    "In Germany these numbers are calculated and published  by RKI. Unfortunately they do not share their code for calculation, so that we have to come up with our own calculation and compare our numbers with the RKI numbers.\n",
    "\n",
    "The so established calculation procedure can then be applied globally to get an overview of the reproduction number in different regions worldwide.\n",
    "\n",
    "## Data Source - RKI\n",
    "What is special about the RKI data?\n",
    "\n",
    "It has the patients linelist and the overall case numbers information combined. The data catalogue can be found here <<https://www.arcgis.com/home/item.html?id=dd4580c810204019a7b8eb3e0b329dd6>>\n",
    "\n",
    "For the global calculation one needs to combine multiple datasources to get the same data, e.g. use the global linelist from beoutbreakprepared <<https://github.com/beoutbreakprepared/nCoV2019/tree/8b8a11a93f99a2814a809ab9b6a7bc0f94db576a/latest_data>> with data catalogue here <<https://www.nature.com/articles/s41597-020-0448-0>> in combination with Johns Hopkins casenumbers <<https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/>>.\n",
    "\n",
    "## Calculation Procedure\n",
    "\n",
    "The calculation of R_eff consists of multiple calculation\n",
    "\n",
    "### Imputation\n",
    "\n",
    "At first the datapoints with missing symptoms-onset date are imputed. Therefor for all datapoints for which we have the reporting and the symptoms onset date the reporting delay is calculated. Then a Weibull distribution is fitted for the reporting delay. This distribution is then applied to the datapoints with missing symptoms onset date for assigning a certain reporting delay to these datapoints and calculate the symptons onset date.\n",
    "\n",
    "### Nowcasting\n",
    "\n",
    "The same distribution is then used to adapt the casenumbers to account for possible cases which will be reported in the future with symptoms onset date until today.\n",
    "\n",
    "### Rolling Window Ratio\n",
    "\n",
    "The calculation of r_eff itself is performed as a summation of casenumbers within a certain timeperiod. RKI uses 4 days. Then the ratio of two sums is compared. Here RKI also compares the sums with 4 days inbetween.\n",
    "\n",
    "## Comparison with official published numbers\n",
    "\n",
    "RKI does not publish their code for calculating the r_eff numbers, but does publish the numbers itself (nowcasted and r_eff values). So we can compare and validate our calculation procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Toggling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import weibull_min \n",
    "from datetime import date \n",
    "import ipywidgets as widgets\n",
    "import difflib\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import of RKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw unprocessed data\n",
    "df_rki=pd.read_csv(\"https://www.arcgis.com/sharing/rest/content/items/f10774f1c63e40168479a1feb6c7ca74/data\")\n",
    "# processed data: summed over all \"Landkreise\" and sorted according to \"Meldedatum\"\n",
    "df_rki_melde=pd.read_csv(\"../RKI_ConfirmedCases_ReportingDate.csv\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proove whether data is up-to-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rki[\"Datenstand\"].unique())\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the logic check to get all new cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rki_temp = df_rki[((df_rki[\"NeuerFall\"]==0) | (df_rki[\"NeuerFall\"]==1))]\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for visualization purposes: Plot the case numbers for each \"Landkreis\" (regional levl in Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the casenumbers\n",
    "fig=plt.figure(figsize=(12,10))\n",
    "ax1=fig.add_subplot(111)\n",
    "#ax.xaxis.set_major_formatter(daysFmt)\n",
    "\n",
    "df_rki_lk=df_rki_temp.groupby([\"Landkreis\",\"Meldedatum\"],as_index=False)[[\"AnzahlFall\"]].sum()\n",
    "for i in df_rki_lk[\"Landkreis\"].unique():\n",
    "    df=df_rki_lk[df_rki_lk[\"Landkreis\"]==i]\n",
    "    df.set_index(\"Meldedatum\", inplace=True, drop=True)\n",
    "    df.index=pd.to_datetime(df.index,format=\"%Y-%m-%d\")\n",
    "    df.sort_index(inplace=True)\n",
    "    ax1.plot(df[\"AnzahlFall\"],color=\"grey\",alpha=0.3)\n",
    "\n",
    "    if \"Berlin\" in i:\n",
    "        df_b=df\n",
    "\n",
    "df_rki_melde.index=pd.to_datetime(df_rki_melde.index,format=\"%Y-%m-%d\")\n",
    "ax1.plot(df_rki_melde[\"AnzahlFall\"],color=\"blue\",label=\"Germany\")\n",
    "ax1.plot(df_b[\"AnzahlFall\"],color=\"red\",label=\"Berlin\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Casenumbers - Reporting Date - for each Landkreis in Germany\")\n",
    "#plt.legend()\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the sliding window size for the R_eff calculation (RKI uses 4 days).\n",
    "\n",
    "This value is used for the summation of cases (e.g. sum of cases 2020-04-05 - 2020-04-08) as well as for the calculation of the ratio (e.g. sum(2020-05-06)/sum(2020-05-09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the timewindow for sliding window\n",
    "# RKI uses 7 days:\n",
    "window=widgets.IntSlider(\n",
    "    value=7,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Sliding time window',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "display(window)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for padding the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine for padding the timeseries\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "date_index=pd.date_range(start='01/01/2020',end=date.today(),freq='D')\n",
    "\n",
    "def filldates(df):\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df=df.asfreq(\"1D\",fill_value=0.0).reindex(date_index,fill_value=0.0)\n",
    "    return df\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine to create a linelist from the RKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to create a linelist from the RKI data\n",
    "def create_linelist(df_rki):\n",
    "    HELP1=[]\n",
    "    HELP2=[]\n",
    "    for index,row in df_rki.iterrows():\n",
    "        i=1\n",
    "        while i<=row[\"AnzahlFall\"]:\n",
    "            HELP1.append(row[\"Meldedatum\"])\n",
    "            HELP2.append(row[\"Refdatum\"])\n",
    "            i+=1\n",
    "\n",
    "    HELP1=pd.to_datetime(HELP1)\n",
    "    HELP2=pd.to_datetime(HELP2)\n",
    "    df_linelist=pd.DataFrame(columns=[\"Meldedatum\",\"Erkrankungsdatum\"],data=list(zip(HELP1,HELP2)))\n",
    "\n",
    "    # list with only valid dates, delay > 0 days    \n",
    "    df_linelist_clean=df_linelist[df_linelist[\"Meldedatum\"]>df_linelist[\"Erkrankungsdatum\"]]\n",
    "    \n",
    "    # Include the delay of 0 days for cases where we do not have the symptoms onset date.\n",
    "    df_linelist.loc[:,\"delay\"]=df_linelist[\"Meldedatum\"]-df_linelist[\"Erkrankungsdatum\"]\n",
    "    # to use for cw as a covariate!\n",
    "    df_linelist.loc[:,\"cw\"]=[i.isocalendar()[1] for i in df_linelist[\"Meldedatum\"]]\n",
    "\n",
    "    # just for the cases where we do have both dates\n",
    "    df_linelist_clean.loc[:,\"delay\"]=df_linelist_clean[\"Meldedatum\"]-df_linelist_clean[\"Erkrankungsdatum\"]\n",
    "    # to use for cw as a covariate!\n",
    "    df_linelist_clean.loc[:,\"cw\"]=[i.isocalendar()[1] for i in df_linelist_clean[\"Meldedatum\"]]\n",
    "    \n",
    "    return df_linelist, df_linelist_clean\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for performing the imputation - Fitting Weibull Distribution for reporting delay, according to: https://www.medrxiv.org/content/10.1101/2020.03.18.20037473v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine for performing the imputation \n",
    "# Fitting Weibull Distribution\n",
    "def imputation(df_linelist,df_linelist_clean):\n",
    "    shape, loc, scale = weibull_min.fit(df_linelist_clean[\"delay\"].dt.days, floc=0)\n",
    "    wb_row=[name,shape,loc,scale]\n",
    "    \n",
    "# distribute missing values accordingly to that distribution:\n",
    "# create random numbers and assign to the missing delay values in the dataframe:\n",
    "# overall values\n",
    "    size=len(df_linelist)\n",
    "    r=weibull_min.rvs(shape,loc=loc,scale=scale,size=size)\n",
    "    df_linelist.loc[:,\"delay_weibull\"]=[datetime.timedelta(days=int(i)) for i in r]\n",
    "    df_linelist.loc[:,\"Erkrankungsdatum Weibull\"]=df_linelist[\"Meldedatum\"]-df_linelist[\"delay_weibull\"]\n",
    "    #print(np.mean(df_linelist[\"delay_weibull\"]))\n",
    "\n",
    "# combine the known values with the imputated values:\n",
    "    df_linelist.loc[df_linelist[\"delay\"].dt.days<=0,\"Combined\"]=df_linelist.loc[df_linelist[\"delay\"].dt.days<=0,\"Erkrankungsdatum Weibull\"]\n",
    "    df_linelist.loc[df_linelist[\"delay\"].dt.days>0,\"Combined\"]=df_linelist.loc[df_linelist[\"delay\"].dt.days>0,\"Erkrankungsdatum\"]\n",
    "\n",
    "    onset_combined=df_linelist[\"Combined\"].value_counts()\n",
    "    \n",
    "# padding the timeseries data to get an entry for every day\n",
    "    onset_combined.sort_index(inplace=True)\n",
    "    onset_combined=onset_combined.asfreq(\"1D\",fill_value=0.0).reindex(date_index,fill_value=0.0)\n",
    "    \n",
    "    number=max(df_linelist[\"delay\"].dt.days)\n",
    "    \n",
    "# calculate p_delay for nowcasting routine\n",
    "    p_delay=pd.Series(data=weibull_min.pdf(np.arange(0,number),shape,loc=loc,scale=scale),index=np.arange(0,number))\n",
    "  \n",
    "    return onset_combined,p_delay,wb_row\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowcasting routine - taken from rt.live (https://github.com/k-sys/covid-19/blob/master/Realtime%20Rt%20mcmc.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nowcasting Routine from rt.live\n",
    "\n",
    "def adjust_onset_for_right_censorship(onset, p_delay):\n",
    "    cumulative_p_delay = p_delay.cumsum()\n",
    "    \n",
    "    # Calculate the additional ones needed so shapes match\n",
    "    ones_needed = len(onset) - len(cumulative_p_delay)\n",
    "    padding_shape = (0, ones_needed)\n",
    "    \n",
    "    # Add ones and flip back\n",
    "    cumulative_p_delay = np.pad(\n",
    "        cumulative_p_delay,\n",
    "        padding_shape,\n",
    "        mode=\"constant\",\n",
    "        constant_values=1)\n",
    "    cumulative_p_delay = np.flip(cumulative_p_delay)\n",
    "    \n",
    "    # Adjusts observed onset values to expected terminal onset values\n",
    "    adjusted = onset / cumulative_p_delay\n",
    "    \n",
    "    return adjusted, cumulative_p_delay\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for performing the r_eff calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine for performing the r_eff calculation\n",
    "def calculate_reff(onset_adjusted):\n",
    "    df_rolling=onset_adjusted.rolling(window.value).sum()\n",
    "    r_t=df_rolling.pct_change(periods=window.value)+1.0\n",
    "    r_t.sort_index(inplace=True)\n",
    "    return r_t\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicheckbox from github --> https://gist.github.com/pbugnion/5bb7878ff212a0116f0f1fbc9f431a5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multicheckbox from github\n",
    "\n",
    "def multi_checkbox_widget(descriptions):\n",
    "    \"\"\" Widget with a search field and lots of checkboxes \"\"\"\n",
    "    search_widget = widgets.Text()\n",
    "    options_dict = {description: widgets.Checkbox(description=description, value=False) for description in descriptions}\n",
    "    options = [options_dict[description] for description in descriptions]\n",
    "    options_widget = widgets.VBox(options, layout={'overflow': 'scroll'})\n",
    "    multi_select = widgets.VBox([search_widget, options_widget])\n",
    "\n",
    "    # Wire the search field to the checkboxes\n",
    "    def on_text_change(change):\n",
    "        search_input = change['new']\n",
    "        if search_input == '':\n",
    "            # Reset search field\n",
    "            new_options = [options_dict[description] for description in descriptions]\n",
    "        else:\n",
    "            # Filter by search field using difflib.\n",
    "            close_matches = difflib.get_close_matches(search_input, descriptions, cutoff=0.0)\n",
    "            new_options = [options_dict[description] for description in close_matches]\n",
    "        options_widget.children = new_options\n",
    "\n",
    "    search_widget.observe(on_text_change, names='value')\n",
    "    return multi_select\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the calculation procedure is performed for each Landkreis and the results (numbers and weibull coefficients) are stored in df's\n",
    "- create linelist\n",
    "- imputation\n",
    "- nowcasting\n",
    "- r_eff calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the complete calculation for all Landkreise:\n",
    "data=[]\n",
    "imputed=pd.DataFrame(index=date_index)\n",
    "nowcast=pd.DataFrame(index=date_index)\n",
    "r_eff=pd.DataFrame(index=date_index)\n",
    "\n",
    "grouped=df_rki_temp.groupby(\"Landkreis\")\n",
    "for name, df in grouped:\n",
    "    # create linelist\n",
    "    df_linelist, df_linelist_clean = create_linelist(df)\n",
    "    # perform imputation\n",
    "    onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean)\n",
    "    # perform nowcasting\n",
    "    onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay)\n",
    "    # calculate r_t\n",
    "    r_t=calculate_reff(onset_adjusted)\n",
    "\n",
    "    # add the Series data to the DataFrames\n",
    "    imputed[name]=onset_combined\n",
    "    nowcast[name]=onset_adjusted\n",
    "    r_eff[name]=r_t\n",
    "    data.append(wb_row)\n",
    "    \n",
    "# save the curve parameters to a dataframe    \n",
    "df_wb=pd.DataFrame(columns=[\"LK\",\"shape\",\"loc\",\"scale\"],data=data)\n",
    "df_wb=df_wb.set_index(\"LK\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the calculation for all LK's in Berlin to get an overall result for Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the calculation for Berlin:\n",
    "lk=[i for i in df_rki_temp[\"Landkreis\"].unique() if \"Berlin\" in i]\n",
    "df=df_rki_temp[df_rki_temp[\"Landkreis\"].isin(lk)] \n",
    "# create linelist\n",
    "df_linelist, df_linelist_clean = create_linelist(df)\n",
    "# perform imputation\n",
    "onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean)\n",
    "# perform nowcasting\n",
    "onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay)\n",
    "# calculate r_t\n",
    "r_t=calculate_reff(onset_adjusted)\n",
    "# add the Series data to the DataFrames\n",
    "imputed[\"Berlin\"]=onset_combined\n",
    "nowcast[\"Berlin\"]=onset_adjusted\n",
    "r_eff[\"Berlin\"]=r_t\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the calculation for all LK's to get an overall result for Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the calculation for overall Germany:\n",
    "# create linelist\n",
    "df_linelist, df_linelist_clean = create_linelist(df_rki_temp)\n",
    "# perform imputation\n",
    "# this can also be done with calendar week as a covariate!\n",
    "onset_combined,p_delay,wb_row = imputation(df_linelist,df_linelist_clean)\n",
    "# perform nowcasting\n",
    "onset_adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset_combined, p_delay)\n",
    "# calculate r_t\n",
    "r_t=calculate_reff(onset_adjusted)\n",
    "# add the Series data to the DataFrames\n",
    "imputed[\"Germany\"]=onset_combined\n",
    "nowcast[\"Germany\"]=onset_adjusted\n",
    "r_eff[\"Germany\"]=r_t\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection Checkbox for selection of LK's for plotting the r_eff values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_plot = multi_checkbox_widget(nowcast.columns.values)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_plot # Display the widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot r_eff for the selected LK's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for automated run within a job: set a default selection\n",
    "names=[\"Berlin\",\"Germany\"]\n",
    "\n",
    "#names=[w.description for w in select_plot.children[1].children if w.value]\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for name in names:\n",
    "    print(name)\n",
    "    ax.plot(r_eff.index,r_eff[name],label=name)\n",
    "ax.hlines(y=1.0,xmin=min(r_eff.index),xmax=max(r_eff.index),lw=1.0)\n",
    "plt.ylim([0,4])\n",
    "plt.legend()\n",
    "plt.title(\"Reproduction number for selected Landkreise\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / Validation / Visualization for Germany and Comparison with official published numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of published numbers (as of 2020-07-16) <<https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Projekte_RKI/Nowcasting_Zahlen.html>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich mit nowcasting werten des RKI\n",
    "df=pd.read_excel(\"../Nowcasting_Zahlen.xlsx\",sheet_name=\"Nowcast_R\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization / Exploration for Germany's reporting delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization / Exploration for Germany\n",
    "print(\"cases with given symptoms onset date: \",len(df_linelist_clean))\n",
    "print(\"cases with missing symptoms onset date: \",len(df_linelist)-len(df_linelist_clean),\n",
    "     (len(df_linelist)-len(df_linelist_clean))/len(df_linelist)*100,\"%\")\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df_linelist_clean[\"delay\"].dt.days, density=True, alpha=0.5,bins=50,color=\"blue\")\n",
    "x = np.linspace(df_linelist_clean[\"delay\"].dt.days.min(), df_linelist_clean[\"delay\"].dt.days.max(), 100) \n",
    "plt.plot(x, weibull_min(wb_row[1], wb_row[2], wb_row[3]).pdf(x),color=\"black\") \n",
    "plt.title(\"Histogram and fitted Weibull distribution for the reporting delay\")\n",
    "print(\"delay mean:\",np.mean(df_linelist_clean[\"delay\"].dt.days))\n",
    "print(\"delay median:\",np.median(df_linelist_clean[\"delay\"].dt.days))\n",
    "print(\"delay std\",np.std(df_linelist_clean[\"delay\"].dt.days))\n",
    "print(\"could be a lot of different curves for cw's\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a plot to compare the reported cases with symptoms onset date with our imputed datasets\n",
    "- using only the imputed dates (applying the weibull delay distribution to all datapoints)\n",
    "- using a combination of reported cases and imputed datapoints, only when there was no symptons onset date given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reported cases with onset symptoms date and the imputed\n",
    "# compare with the nowcasted values from RKI:\n",
    "onset_imputed=df_linelist[\"Erkrankungsdatum Weibull\"].value_counts()\n",
    "onset_real=df_linelist_clean[\"Erkrankungsdatum\"].value_counts()\n",
    "#onset_imputed_rki=df_rki_cw[\"Erkrankungsdatum Weibull\"].value_counts()\n",
    "onset_imputed.sort_index(inplace=True)\n",
    "onset_real.sort_index(inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.plot(onset_real, color=\"black\", label=\"given symptoms onset date\")\n",
    "plt.plot(onset_imputed,\"g-.\", label=\"only imputed symptoms onset date\")\n",
    "plt.plot(onset_combined,color=\"red\",label=\"combined imputed/given symptoms onset date\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison: Imputation applied to all datapoints / mising datapoints\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it is no good fit when the imputation is applied to all datapoints, so we rather go with the combined dataset!\n",
    "\n",
    "In the next plot we compare our nowcasted values (based on the combined imputed timeseries) with the nowcast values from RKI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.plot(onset_real, color=\"black\", label=\"given symptoms onset date\")\n",
    "plt.plot(onset_combined,color=\"red\",label=\"combined imputed/given symptoms onset date\")\n",
    "plt.plot(onset_adjusted,\"g-.\", label=\"nowcasted symptoms onset date\")\n",
    "plt.plot(df[\"Datum des Erkrankungsbeginns\"],df[\"Punktschätzer der Anzahl Neuerkrankungen\"],\"g:\",label=\"nowcasted values from RKI\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Nowcasted Values\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a good fit between our values and the RKI values, so the applied methods seem to be correct.\n",
    "\n",
    "Open questions are still:\n",
    "- For how many cases does one need the symptoms onset date given to get a \"valid\" distribution.\n",
    "\n",
    "In the next plot we take a look at the calculated r_eff and the RKI r_eff values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.plot(r_t,\"k--\",label=\"r_eff\")\n",
    "ax.plot(df[\"Datum des Erkrankungsbeginns\"],df[\"Punktschätzer der Reproduktionszahl R\"], label=\"r_eff RKI\")\n",
    "ax.hlines(y=1.0,xmin=min(r_eff.index),xmax=max(r_eff.index),lw=1.0)\n",
    "plt.ylim([0,4])\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of r_eff\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Extension: Perform the Weibull fitting with the calendar week as a covariate.\n",
    "This takes into account, that the reporting routines and procedures do change during the pandemic\n",
    "\n",
    "We rerun the part for overall Germany, and just using another routine for the fitting the Weibull distribution.\n",
    "\n",
    "In the created linelists we already introduced another column for the calendarweek, of which we can make use now.\n",
    "\n",
    "Then we plot all Weibull curves for all calendar weeks to the deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do the calculation for overall Germany - with calendar week as covariate:\n",
    "# create linelist\n",
    "df_linelist, df_linelist_clean = create_linelist(df_rki_temp)\n",
    "\n",
    "# fit Weibull distributions for every calendar week\n",
    "data=[]\n",
    "grouped=df_linelist_clean.groupby(\"cw\")\n",
    "for name,group in grouped:\n",
    "    shape, loc, scale = weibull_min.fit(group[\"delay\"].dt.days, floc=0)\n",
    "    row=[name,shape,loc,scale]\n",
    "    data.append(row)\n",
    "\n",
    "# dataframe with Weibull coefficients for every calendar week\n",
    "df_wb=pd.DataFrame(columns=[\"cw\",\"shape\",\"loc\",\"scale\"],data=data)\n",
    "df_wb=df_wb.set_index(\"cw\")\n",
    "\n",
    "# just for comparison: Weibull shape parameters for overall data (redoing the former calculation)\n",
    "shape_ges, loc_ges, scale_ges = weibull_min.fit(df_linelist_clean[\"delay\"].dt.days, floc=0)\n",
    "\n",
    "# plot the curves\n",
    "x = np.linspace(df_linelist_clean[\"delay\"].dt.days.min(), df_linelist_clean[\"delay\"].dt.days.max(), 100) \n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for row in df_wb.iterrows():\n",
    "    ax.plot(x, weibull_min(row[1][0], row[1][1],row[1][2]).pdf(x),label=row[0])\n",
    "ax.plot(x, weibull_min(shape_ges, loc_ges, scale_ges).pdf(x),color=\"black\") \n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Fitted Weibull Curves for the reporting delay for each calendar week\")\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes for imputed / nowcasted and r_eff numbers for all Landkreise in Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('/project_data/data_asset/venus/r_eff_numbers_germany/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('/project_data/data_asset/venus/r_eff_numbers_germany/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(imputed,\"imputed\")\n",
    "imputed.to_csv(\"../imputed.csv\",index_label=False)\n",
    "#imputed=load_obj(\"imputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(nowcast,\"nowcast\")\n",
    "nowcast.to_csv(\"../nowcast.csv\",index_label=False)\n",
    "#nowcast=load_obj(\"nowcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(r_eff,\"r_eff\")\n",
    "r_eff.to_csv(\"../r_eff.csv\",index_label=False)\n",
    "#r_eff=load_obj(\"r_eff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(df_wb,\"df_wb\")\n",
    "df_wb.to_csv(\"../df_wb.csv\",index_label=False)\n",
    "#r_eff=load_obj(\"df_wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
