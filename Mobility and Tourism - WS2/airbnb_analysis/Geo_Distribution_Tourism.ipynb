{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-Distribution of Tourism #\n",
    "\n",
    "The tourism industry has been masively affected by the Covid-19 situation. One of the indicators for travelling is the number of Airbnb reviews, treated here as demand.\n",
    "\n",
    "This notebook extracts the data from InsideAirbnb, aggregates it and displays the number of reviews for each neighbourhood per month.\n",
    "\n",
    "### Inputs: ###\n",
    "<br>Bristol_reviews.csv - This dataset is the reviews file downloaded from http://insideairbnb.com/get-the-data.html. It contains all the reviews up to the last scraped date. <br/>\n",
    "<br> Bristol_listings.csv - This dataset is the listings file downloaded from http://insideairbnb.com/get-the-data.html. It contains the listings of that specific month. <br/>\n",
    "<br>neighbourhoods.geojson - This dataset is the geojson file downloaded from http://insideairbnb.com/get-the-data.html. It contains the geometry of the neighbourhoods.\n",
    "\n",
    "\n",
    "### Steps ###\n",
    "\n",
    "1. Get the number of reviews per day per city.\n",
    "2. Get the number of reviews per day per district.\n",
    "3. Normalize teh number of reviews for each month.\n",
    "4. Plot each neighbourhood for a given month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the dependencies\n",
    "\n",
    "!pip install shapely\n",
    "!pip install geopandas\n",
    "!pip install geojsonio\n",
    "!pip install descartes\n",
    "!pip install wget\n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import wget\n",
    "from os.path import isfile\n",
    "from os import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the airbnb website and fetch the name and links to all available data files\n",
    "\n",
    "r = requests.get(\"http://insideairbnb.com/get-the-data.html\")\n",
    "soup = BeautifulSoup(r.text)\n",
    "alldata = {}\n",
    "\n",
    "for table in tqdm(soup.findAll(\"table\", {\"class\":\"table-hover\"})):\n",
    "    df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "    df[\"downloadlink\"] = \"\"\n",
    "    index = 0\n",
    "    for link in table.findAll(\"a\",href=True):\n",
    "        df.at[index,\"downloadlink\"] = link[\"href\"]\n",
    "        index += 1\n",
    "    city = df[\"Country/City\"].unique()[0]\n",
    "    alldata[city] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reviews per day per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_for_city(city_name):\n",
    "    city_name = city_name.replace(\" \", \"_\")\n",
    "    filename = f\"{city_name}_reviews.csv\"\n",
    "    if not isfile(filename):\n",
    "        return None\n",
    "    df = pd.read_csv(filename)    \n",
    "    df[\"number_of_reviews\"] = 1\n",
    "    df = df[[\"date\", \"number_of_reviews\"]]\\\n",
    "            .groupby(\"date\")\\\n",
    "            .sum()\\\n",
    "            .reset_index(drop=False)\\\n",
    "            .rename(columns={\n",
    "                \"number_of_reviews\": city_name}\n",
    "            )\n",
    "    df = df[df[\"date\"] != \"0\"]\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.set_index(\"date\", drop=True, inplace=True)\n",
    "    df = df.astype(float)\n",
    "    df = df.resample('D').mean()\n",
    "    t_index = pd.DatetimeIndex(start='2014-01-01', end='2020-06-30', freq='D')\n",
    "    df = df.interpolate(method='linear', limit_area=\"inside\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all the reviews for all the cities available on insideairbnb in one DataFrame\n",
    "\n",
    "city_names = list(alldata.keys())\n",
    "df_final = pd.DataFrame()\n",
    "for idx, city_name in enumerate(city_names):\n",
    "    print(\"City: \", city_name)\n",
    "    if idx > 1000000:\n",
    "        break\n",
    "    df = get_reviews_for_city(city_name)\n",
    "    if df is not None:\n",
    "        df_final = pd.concat([df_final, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of reviews over time for Bristol and London\n",
    "\n",
    "fig = df_final[[\"Bristol\", \"London\"]].plot(figsize=(20, 10),fontsize= 16)\n",
    "fig.legend(fontsize =16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reviews per day per district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utility functions\n",
    "\n",
    "def get_geojson_url(city_name):\n",
    "    df_city_info = alldata[city_name]\n",
    "    df_city_info = df_city_info[df_city_info[\"File Name\"] == \"neighbourhoods.geojson\"]\n",
    "    return df_city_info[\"downloadlink\"].iloc[0]\n",
    "\n",
    "def download_geojson(geojson_url):\n",
    "    if isfile(\"neighbourhoods.geojson\"):\n",
    "        remove(\"neighbourhoods.geojson\")\n",
    "    wget.download(geojson_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe with all the reviews of a given city, per district.\n",
    "\n",
    "def get_reviews_by_district(city_name):\n",
    "    \n",
    "    geojson_url = get_geojson_url(city_name)\n",
    "    download_geojson(geojson_url)\n",
    "    if not isfile('neighbourhoods.geojson'):\n",
    "        return None\n",
    "    df_places = gpd.read_file('neighbourhoods.geojson')\n",
    "    df_places[\"neighbourhood\"] = df_places[\"neighbourhood\"].astype(str)\n",
    "    \n",
    "    city_name = city_name.replace(\" \", \"_\")\n",
    "    filename = f\"{city_name}_listings.csv\"\n",
    "    if not isfile(filename):\n",
    "        return None\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[[\"id\", \"neighbourhood_cleansed\"]]\n",
    "    df.drop_duplicates(subset=[\"id\"], keep=\"first\", inplace=True)\n",
    "    df[\"neighbourhood_cleansed\"] = df[\"neighbourhood_cleansed\"].astype(str)\n",
    "\n",
    "    df = pd.merge(df, df_places, left_on=\"neighbourhood_cleansed\", right_on=\"neighbourhood\", how=\"left\")\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df[[\"id\", \"neighbourhood\", \"geometry\"]]\n",
    "    \n",
    "    filename = f\"{city_name}_reviews.csv\"\n",
    "    if not isfile(filename):\n",
    "        return None\n",
    "    df_reviews = pd.read_csv(filename) \n",
    "    df = pd.merge(df, df_reviews, left_on=\"id\", right_on=\"listing_id\", how=\"right\")\n",
    "    df[\"yearmonth\"] = df[\"date\"].apply(lambda x: str(x)[:7])\n",
    "    print(df)\n",
    "    df.drop([\"listing_id\", \"date\"], axis=1, inplace=True)\n",
    "\n",
    "    df[\"n_reviews\"] = 1\n",
    "    df = df.groupby([\"neighbourhood\", \"yearmonth\"]).agg({\n",
    "            \"geometry\": lambda x: x.iloc[0],\n",
    "            \"n_reviews\": sum\n",
    "        }).reset_index(drop=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reviews_by_district(\"Bristol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the number of reviews for each month##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yearmonth in df.yearmonth.unique():\n",
    "    idx = df[df[\"yearmonth\"] == yearmonth].index\n",
    "    _sum = df[df[\"yearmonth\"] == yearmonth][\"n_reviews\"].sum()\n",
    "    df.iloc[idx, 3] = 100 * (df.iloc[idx, 3] / _sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot each neighbourhood for a given month##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a month and plot the map of the chosen city to see how many bookings were made in each district\n",
    "\n",
    "MONTH = \"2020-04\"\n",
    "gdf = gpd.GeoDataFrame(df[df[\"yearmonth\"]==MONTH], \n",
    "                       geometry=\"geometry\")\n",
    "gdf.plot(column=\"n_reviews\", \n",
    "         figsize=(20, 20),\n",
    "         cmap=\"Blues\", \n",
    "         linewidth=0.8, \n",
    "         edgecolor=\"0.8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
